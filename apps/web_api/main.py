"""FastAPI web application."""
import sys
from pathlib import Path
import os
import shutil
from datetime import datetime
from uuid import uuid4
from typing import List, Optional
import json

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from fastapi import FastAPI, File, UploadFile, HTTPException, Depends, Query
from fastapi.responses import HTMLResponse, StreamingResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel, Field
from sqlalchemy.orm import Session
from sse_starlette.sse import EventSourceResponse

from packages.core.config import get_settings
from packages.core.database import (
    get_db,
    Document,
    DocumentStatus,
    ChunkProfile,
    get_session_maker,
)
from packages.core.loaders import compute_file_sha256
from packages.core.kafka_utils import send_ingest_event, send_reindex_event
from packages.core.retrieval import retrieve_chunks, format_citations, build_rag_context
from packages.core.vllm_client import get_vllm_client, build_rag_prompt
from packages.core.logging_config import setup_logging

logger = setup_logging("web_api")

TAGS_SYSTEM = "System"
TAGS_DOCUMENTS = "Documents"
TAGS_CHUNK_PROFILES = "Chunk Profiles"
TAGS_REINDEX = "Reindex"
TAGS_CHAT = "Chat"

app = FastAPI(
    title="AI Knowledge Bench",
    description="RAG knowledge assistant with evaluation harness",
    version="0.1.0",
    openapi_tags=[
        {
            "name": TAGS_SYSTEM,
            "description": "ç³»ç»Ÿä¸åŸºç¡€èƒ½åŠ›ï¼ˆå¥åº·æ£€æŸ¥ã€ç®€å• UIï¼‰ã€‚",
        },
        {
            "name": TAGS_DOCUMENTS,
            "description": "æ–‡æ¡£ä¸Šä¼ ä¸æ–‡æ¡£åˆ—è¡¨ï¼ˆè§¦å‘å¼‚æ­¥å…¥åº“/ç´¢å¼•ï¼‰ã€‚",
        },
        {
            "name": TAGS_CHUNK_PROFILES,
            "description": "åˆ†å—ç­–ç•¥é…ç½®ï¼ˆchunk size / overlap / æ¿€æ´»çš„ profileï¼‰ã€‚",
        },
        {
            "name": TAGS_REINDEX,
            "description": "é‡å»ºç´¢å¼•ï¼ˆé€šè¿‡ Kafka è§¦å‘å¼‚æ­¥é‡å¤„ç†ï¼‰ã€‚",
        },
        {
            "name": TAGS_CHAT,
            "description": "æ£€ç´¢ + RAG + LLM çš„ SSE æµå¼å¯¹è¯æ¥å£ã€‚",
        },
    ],
)

settings = get_settings()

# Ensure upload directory exists
os.makedirs(settings.app_upload_dir, exist_ok=True)


# Pydantic models
class DocumentResponse(BaseModel):
    """æ–‡æ¡£æ¥å£çš„è¿”å›æ¨¡å‹ï¼ˆè½»é‡è§†å›¾ï¼‰ã€‚

    ä¸»è¦ç”¨äºä¸Šä¼ åå›æ˜¾ï¼Œä»¥åŠåˆ—è¡¨å±•ç¤ºã€‚
    å¦‚éœ€è§‚å¯Ÿâ€œå…¥åº“/ç´¢å¼•è¿›åº¦â€ï¼Œè¯·è½®è¯¢ `GET /v1/documents` å¹¶æŸ¥çœ‹ `status`ã€‚
    """

    id: str = Field(..., description="æ–‡æ¡£ UUIDã€‚", examples=["14b1f61b-1842-455d-b31c-7f0882bb1729"])
    filename: str = Field(..., description="ç”¨æˆ·ä¸Šä¼ æ—¶çš„åŸå§‹æ–‡ä»¶åã€‚", examples=["README.md"])
    mime_type: Optional[str] = Field(
        None,
        description="å®¢æˆ·ç«¯æŠ¥å‘Šçš„ MIME typeï¼›ä¸åŒå®¢æˆ·ç«¯/æµè§ˆå™¨å¯èƒ½ä¸ºç©ºã€‚",
        examples=["text/markdown"],
    )
    file_size: int = Field(..., description="æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰ã€‚", examples=[14225])
    status: str = Field(
        ...,
        description="å…¥åº“/ç´¢å¼•çŠ¶æ€ã€‚å¸¸è§å€¼ï¼šuploaded / ingesting / ready / failedã€‚",
        examples=["ingesting"],
    )
    created_at: str = Field(
        ...,
        description="æ–‡æ¡£è®°å½•åˆ›å»ºæ—¶é—´ï¼ˆUTCï¼ŒISO 8601ï¼‰ã€‚",
        examples=["2026-01-31T08:27:42.151214"],
    )
    id: str
    filename: str
    mime_type: Optional[str]
    file_size: int
    status: str
    created_at: str


class ChunkProfileCreate(BaseModel):
    """åˆ›å»ºåˆ†å—ç­–ç•¥ï¼ˆchunk profileï¼‰çš„è¯·æ±‚æ¨¡å‹ã€‚

    chunk profile ç”¨äºæ§åˆ¶ï¼šæ–‡æ¡£å¦‚ä½•åˆ‡åˆ†æˆ chunkï¼Œå†å¯¹ chunk åš embedding å¹¶å†™å…¥å‘é‡è¡¨ã€‚
    """

    name: str = Field(..., description="profile åç§°ï¼ˆéœ€å”¯ä¸€ï¼‰ã€‚", examples=["default"])
    description: Optional[str] = Field(None, description="æè¿°ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰ã€‚", examples=["é»˜è®¤åˆ†å—ç­–ç•¥"])
    chunk_size: int = Field(..., description="chunk å¤§å°ï¼ˆå®ç°ç›¸å…³ï¼šå¯èƒ½æ˜¯ token/å­—ç¬¦çš„è¿‘ä¼¼å€¼ï¼‰ã€‚", examples=[512])
    chunk_overlap: int = Field(
        ...,
        description="ç›¸é‚» chunk çš„é‡å å¤§å°ã€‚",
        examples=[128],
    )


class ChunkProfileResponse(BaseModel):
    """chunk profile çš„è¿”å›æ¨¡å‹ã€‚"""

    id: str = Field(..., description="chunk profile UUIDã€‚")
    name: str = Field(..., description="profile åç§°ã€‚")
    description: Optional[str] = Field(None, description="profile æè¿°ã€‚")
    chunk_size: int = Field(..., description="chunk å¤§å°ã€‚")
    chunk_overlap: int = Field(..., description="chunk é‡å å¤§å°ã€‚")
    is_active: bool = Field(..., description="æ˜¯å¦ä¸ºå½“å‰æ¿€æ´»çš„ profileã€‚")
    created_at: str = Field(..., description="åˆ›å»ºæ—¶é—´ï¼ˆUTCï¼ŒISO 8601ï¼‰ã€‚")


class ReindexRequest(BaseModel):
    """è§¦å‘é‡å»ºç´¢å¼•çš„è¯·æ±‚æ¨¡å‹ã€‚

    é‡å»ºç´¢å¼•å«ä¹‰ï¼šæŒ‰æŒ‡å®š chunk profile é‡æ–°åˆ†å—ï¼Œå¹¶é‡æ–°ç”Ÿæˆ embeddings å†™å…¥å‘é‡è¡¨ã€‚
    æ³¨æ„ï¼šæ­¤æ¥å£åªè´Ÿè´£â€œå‘æ¶ˆæ¯è§¦å‘â€ï¼Œä¸ä¼šåŒæ­¥åšè€—æ—¶è®¡ç®—ï¼›å®é™…å·¥ä½œç”± worker å¼‚æ­¥å®Œæˆï¼ˆKafkaï¼‰ã€‚
    """

    chunk_profile_id: str = Field(..., description="ç”¨äºé‡å»ºç´¢å¼•çš„ chunk profile UUIDã€‚")
    embedding_model: Optional[str] = Field(
        None,
        description="å¯é€‰ï¼šæœ¬æ¬¡é‡å»ºç´¢å¼•ä½¿ç”¨çš„ embedding æ¨¡å‹ã€‚ä¸ºç©ºåˆ™ä½¿ç”¨æœåŠ¡é»˜è®¤é…ç½®ã€‚",
        examples=["intfloat/multilingual-e5-small"],
    )
    document_ids: Optional[List[str]] = Field(
        None,
        description="å¯é€‰ï¼šä»…é‡å»ºè¿™äº› document UUIDï¼›ä¸ºç©ºåˆ™é‡å»ºå…¨éƒ¨ READY æ–‡æ¡£ã€‚",
        examples=[["14b1f61b-1842-455d-b31c-7f0882bb1729"]],
    )


class ChatRequest(BaseModel):
    """å¯¹è¯è¯·æ±‚æ¨¡å‹ï¼ˆç›®å‰ä¸»è¦ç”¨äºæ–‡æ¡£/å‚è€ƒï¼‰ã€‚

    è¯´æ˜ï¼šæœ¬æ–‡ä»¶å®é™…å®ç°çš„æ˜¯ `GET /v1/chat/stream`ï¼ˆSSE æµå¼ï¼‰ï¼Œå¹¶é POST JSONã€‚
    """

    query: str = Field(..., description="ç”¨æˆ·é—®é¢˜ã€‚", examples=["è¿™ä¸ªé¡¹ç›®æ˜¯åšä»€ä¹ˆçš„ï¼Ÿ"])
    top_k: Optional[int] = Field(None, description="æ£€ç´¢ top_kï¼ˆè¿”å› chunk æ•°ï¼‰ã€‚", examples=[5])
    chunk_profile_id: Optional[str] = Field(
        None,
        description="å¯é€‰ï¼šæŒ‡å®š chunk profile UUIDï¼›ä¸ºç©ºåˆ™ä½¿ç”¨å½“å‰æ¿€æ´» profileã€‚",
    )


# Endpoints
@app.get(
    "/",
    response_class=HTMLResponse,
    tags=[TAGS_SYSTEM],
    summary="Web UIï¼ˆHTMLï¼‰",
    description=(
        "æä¾›ä¸€ä¸ªæç®€çš„å•é¡µ HTML UIï¼Œç”¨äºæ‰‹å·¥éªŒè¯ï¼ˆä¸Šä¼  + æµå¼å¯¹è¯ï¼‰ã€‚"
        "ç¨‹åºåŒ–è°ƒç”¨è¯·ä½¿ç”¨ /v1/* æ¥å£ï¼Œå¹¶æŸ¥çœ‹ /docs è‡ªåŠ¨ç”Ÿæˆçš„ OpenAPI æ–‡æ¡£ã€‚"
    ),
)
async def root():
    """è¿”å›ä¸€ä¸ªæç®€ HTML UIã€‚

    è¯¥é¡µé¢ä»…ç”¨äºå¿«é€ŸéªŒè¯ï¼šä¸Šä¼ æ–‡ä»¶ã€å°è¯• SSE æµå¼å¯¹è¯ã€‚
    å¹¶ä¸æ˜¯ä¸€ä¸ªå®Œæ•´çš„å‰ç«¯åº”ç”¨ã€‚
    """
    html_content = """
    <!DOCTYPE html>
    <html>
    <head>
        <title>AI Knowledge Bench</title>
        <style>
            body {
                font-family: Arial, sans-serif;
                max-width: 1200px;
                margin: 0 auto;
                padding: 20px;
                background-color: #f5f5f5;
            }
            .container {
                background: white;
                padding: 30px;
                border-radius: 8px;
                box-shadow: 0 2px 4px rgba(0,0,0,0.1);
                margin-bottom: 20px;
            }
            h1 {
                color: #333;
                border-bottom: 3px solid #4CAF50;
                padding-bottom: 10px;
            }
            h2 {
                color: #555;
                margin-top: 30px;
            }
            .upload-section, .chat-section {
                margin: 20px 0;
            }
            input[type="file"], input[type="text"] {
                padding: 10px;
                margin: 10px 0;
                width: 100%;
                box-sizing: border-box;
                border: 1px solid #ddd;
                border-radius: 4px;
            }
            button {
                background-color: #4CAF50;
                color: white;
                padding: 12px 24px;
                border: none;
                border-radius: 4px;
                cursor: pointer;
                font-size: 16px;
                margin: 5px;
            }
            button:hover {
                background-color: #45a049;
            }
            button:disabled {
                background-color: #ccc;
                cursor: not-allowed;
            }
            .message {
                padding: 10px;
                margin: 10px 0;
                border-radius: 4px;
            }
            .user-message {
                background-color: #e3f2fd;
                text-align: right;
            }
            .assistant-message {
                background-color: #f1f8e9;
            }
            .citations {
                background-color: #fff3cd;
                padding: 15px;
                margin: 10px 0;
                border-radius: 4px;
                border-left: 4px solid #ffc107;
            }
            .citation {
                margin: 8px 0;
                padding: 8px;
                background: white;
                border-radius: 3px;
            }
            #status {
                padding: 10px;
                margin: 10px 0;
                border-radius: 4px;
                display: none;
            }
            .status-success {
                background-color: #d4edda;
                color: #155724;
            }
            .status-error {
                background-color: #f8d7da;
                color: #721c24;
            }
            .loading {
                display: inline-block;
                width: 20px;
                height: 20px;
                border: 3px solid #f3f3f3;
                border-top: 3px solid #4CAF50;
                border-radius: 50%;
                animation: spin 1s linear infinite;
            }
            @keyframes spin {
                0% { transform: rotate(0deg); }
                100% { transform: rotate(360deg); }
            }
        </style>
    </head>
    <body>
        <h1>ğŸ¤– AI Knowledge Bench</h1>
        
        <div class="container">
            <h2>ğŸ“„ Upload Document</h2>
            <div class="upload-section">
                <input type="file" id="fileInput" accept=".pdf,.docx,.pptx,.xlsx,.html,.md,.txt">
                <button onclick="uploadFile()">Upload</button>
                <div id="status"></div>
            </div>
        </div>
        
        <div class="container">
            <h2>ğŸ’¬ Chat</h2>
            <div class="chat-section">
                <input type="text" id="queryInput" placeholder="Ask a question..." onkeypress="if(event.key==='Enter') sendQuery()">
                <button onclick="sendQuery()">Send</button>
                <div id="chatMessages"></div>
                <div id="citations"></div>
            </div>
        </div>
        
        <script>
            async function uploadFile() {
                const fileInput = document.getElementById('fileInput');
                const status = document.getElementById('status');
                const file = fileInput.files[0];
                
                if (!file) {
                    showStatus('Please select a file', 'error');
                    return;
                }
                
                const formData = new FormData();
                formData.append('file', file);
                
                showStatus('Uploading...', 'success');
                
                try {
                    const response = await fetch('/v1/documents', {
                        method: 'POST',
                        body: formData
                    });
                    
                    if (response.ok) {
                        const data = await response.json();
                        showStatus(`File uploaded successfully! Document ID: ${data.id}`, 'success');
                        fileInput.value = '';
                    } else {
                        const error = await response.text();
                        showStatus(`Upload failed: ${error}`, 'error');
                    }
                } catch (error) {
                    showStatus(`Upload error: ${error.message}`, 'error');
                }
            }
            
            async function sendQuery() {
                const queryInput = document.getElementById('queryInput');
                const chatMessages = document.getElementById('chatMessages');
                const citationsDiv = document.getElementById('citations');
                const query = queryInput.value.trim();
                
                if (!query) return;
                
                // Add user message
                addMessage(query, 'user');
                queryInput.value = '';
                
                // Add loading indicator
                const loadingDiv = document.createElement('div');
                loadingDiv.className = 'message assistant-message';
                loadingDiv.id = 'loading';
                loadingDiv.innerHTML = '<div class="loading"></div> Thinking...';
                chatMessages.appendChild(loadingDiv);
                
                try {
                    const response = await fetch(`/v1/chat/stream?query=${encodeURIComponent(query)}`);
                    const reader = response.body.getReader();
                    const decoder = new TextDecoder();
                    
                    // Remove loading indicator
                    loadingDiv.remove();
                    
                    // Create message div for streaming response
                    const messageDiv = document.createElement('div');
                    messageDiv.className = 'message assistant-message';
                    chatMessages.appendChild(messageDiv);
                    
                    let fullResponse = '';
                    let citations = [];
                    
                    while (true) {
                        const {value, done} = await reader.read();
                        if (done) break;
                        
                        const text = decoder.decode(value);
                        const lines = text.split('\\n');
                        
                        for (const line of lines) {
                            if (line.startsWith('data: ')) {
                                const data = line.substring(6);
                                if (data === '[DONE]') continue;
                                
                                try {
                                    const parsed = JSON.parse(data);
                                    if (parsed.type === 'token') {
                                        fullResponse += parsed.content;
                                        messageDiv.textContent = fullResponse;
                                    } else if (parsed.type === 'citations') {
                                        citations = parsed.citations;
                                    }
                                } catch (e) {
                                    console.error('Parse error:', e);
                                }
                            }
                        }
                    }
                    
                    // Display citations
                    if (citations.length > 0) {
                        citationsDiv.innerHTML = '<h3>ğŸ“š Sources</h3>';
                        const citList = document.createElement('div');
                        citations.forEach((cit, idx) => {
                            const citDiv = document.createElement('div');
                            citDiv.className = 'citation';
                            citDiv.innerHTML = `
                                <strong>[${idx + 1}]</strong> ${cit.source_ref}<br>
                                <small>Document: ${cit.document_id.substring(0, 8)}... | Score: ${cit.score.toFixed(3)}</small><br>
                                <em>${cit.snippet}</em>
                            `;
                            citList.appendChild(citDiv);
                        });
                        const wrapper = document.createElement('div');
                        wrapper.className = 'citations';
                        wrapper.appendChild(citList);
                        citationsDiv.appendChild(wrapper);
                    }
                    
                } catch (error) {
                    loadingDiv.remove();
                    addMessage(`Error: ${error.message}`, 'assistant');
                }
            }
            
            function addMessage(content, role) {
                const chatMessages = document.getElementById('chatMessages');
                const messageDiv = document.createElement('div');
                messageDiv.className = `message ${role}-message`;
                messageDiv.textContent = content;
                chatMessages.appendChild(messageDiv);
                chatMessages.scrollTop = chatMessages.scrollHeight;
            }
            
            function showStatus(message, type) {
                const status = document.getElementById('status');
                status.textContent = message;
                status.className = `status-${type}`;
                status.style.display = 'block';
                setTimeout(() => {
                    status.style.display = 'none';
                }, 5000);
            }
        </script>
    </body>
    </html>
    """
    return HTMLResponse(content=html_content)


@app.get(
    "/health",
    tags=[TAGS_SYSTEM],
    summary="å¥åº·æ£€æŸ¥",
    description="å­˜æ´»æ¢é’ˆï¼ˆlivenessï¼‰ã€‚æœåŠ¡è¿›ç¨‹æ­£å¸¸æ—¶è¿”å› 200ã€‚",
)
async def health():
    """å¥åº·æ£€æŸ¥ï¼ˆlivenessï¼‰ã€‚

    è¿”å›ï¼š`{"status": "ok"}`ã€‚
    """
    return {"status": "ok"}


@app.post(
    "/v1/documents",
    response_model=DocumentResponse,
    tags=[TAGS_DOCUMENTS],
    summary="ä¸Šä¼ æ–‡æ¡£",
    description=(
        "ä¸Šä¼ å•ä¸ªæ–‡æ¡£ï¼šä¿å­˜åˆ°ç£ç›˜ã€å†™å…¥ documents è¡¨ï¼Œå¹¶å‘é€ ingest äº‹ä»¶åˆ° Kafkaã€‚"
        "çœŸæ­£çš„è§£æ/åˆ†å—/embedding/å†™å‘é‡è¡¨ç”± worker å¼‚æ­¥å®Œæˆã€‚"
        "\n\nå»é‡ç­–ç•¥ï¼šæŒ‰æ–‡ä»¶ SHA-256 å»é‡ã€‚è‹¥å·²å­˜åœ¨ç›¸åŒ SHA-256 çš„æ–‡æ¡£ï¼Œæœ¬æ¬¡ä¸Šä¼ ä¼šåˆ é™¤é‡å¤æ–‡ä»¶å¹¶ç›´æ¥è¿”å›å·²å­˜åœ¨çš„æ–‡æ¡£è®°å½•ã€‚"
    ),
    responses={
        200: {"description": "Document accepted (or deduplicated) and ingestion scheduled."},
        500: {"description": "Unexpected server error (see logs)."},
    },
)
async def upload_document(
    file: UploadFile = File(...),
    db: Session = Depends(get_db)
):
    """ä¸Šä¼ æ–‡æ¡£å¹¶è§¦å‘å¼‚æ­¥å…¥åº“/ç´¢å¼•ã€‚

    å¤„ç†æµç¨‹ï¼š
        1) å°†ä¸Šä¼ çš„æ–‡ä»¶è½ç›˜åˆ° `APP_UPLOAD_DIR`ã€‚
        2) è®¡ç®— SHA-256 å¹¶æ£€æŸ¥æ˜¯å¦é‡å¤ã€‚
        3) å‘ `documents` è¡¨æ’å…¥è®°å½•ï¼ˆåˆå§‹ status=uploadedï¼‰ã€‚
        4) å‘ Kafka å‘å¸ƒ ingest æ¶ˆæ¯ï¼Œworker å°†å¼‚æ­¥å¤„ç†ï¼ˆè§£æâ†’åˆ†å—â†’embeddingâ†’å†™å‘é‡è¡¨ï¼‰ã€‚

    å‚æ•°ï¼š
        file: multipart æ–‡ä»¶å­—æ®µã€‚
        db: SQLAlchemy ä¼šè¯ï¼ˆä¾èµ–æ³¨å…¥ï¼‰ã€‚

    è¿”å›ï¼š
        DocumentResponseï¼šæ–‡æ¡£åŸºæœ¬ä¿¡æ¯ä¸å½“å‰çŠ¶æ€ã€‚

    å¤‡æ³¨ï¼š
        - è¿”å›çš„ status å¯èƒ½æ˜¯ uploaded æˆ– ingestingï¼ˆå–å†³äº worker æ¶ˆè´¹é€Ÿåº¦ï¼‰ã€‚
        - è¿›åº¦æŸ¥çœ‹ï¼šè½®è¯¢ `GET /v1/documents` æˆ–æŸ¥çœ‹ worker æ—¥å¿—ã€‚
    """
    try:
        # Save file
        file_path = os.path.join(settings.app_upload_dir, f"{uuid4()}_{file.filename}")
        with open(file_path, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)
        
        # Compute hash
        sha256 = compute_file_sha256(file_path)
        
        # Check if document already exists
        existing = db.query(Document).filter(Document.sha256 == sha256).first()
        if existing:
            # Remove duplicate file
            os.remove(file_path)
            logger.info(f"Document already exists: {existing.id}")
            return DocumentResponse(
                id=str(existing.id),
                filename=existing.filename,
                mime_type=existing.mime_type,
                file_size=existing.file_size,
                status=existing.status.value,
                created_at=existing.created_at.isoformat()
            )
        
        # Create document record
        doc = Document(
            id=uuid4(),
            filename=file.filename,
            filepath=file_path,
            mime_type=file.content_type,
            file_size=os.path.getsize(file_path),
            sha256=sha256,
            status=DocumentStatus.UPLOADED,
            created_at=datetime.utcnow(),
            updated_at=datetime.utcnow()
        )
        db.add(doc)
        db.commit()
        db.refresh(doc)
        
        # Send Kafka event for ingestion
        send_ingest_event(str(doc.id))
        
        logger.info(f"Document uploaded: {doc.filename} (ID: {doc.id})")
        
        return DocumentResponse(
            id=str(doc.id),
            filename=doc.filename,
            mime_type=doc.mime_type,
            file_size=doc.file_size,
            status=doc.status.value,
            created_at=doc.created_at.isoformat()
        )
    
    except Exception as e:
        logger.error(f"Error uploading document: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.get(
    "/v1/documents",
    response_model=List[DocumentResponse],
    tags=[TAGS_DOCUMENTS],
    summary="è·å–æ–‡æ¡£åˆ—è¡¨",
    description="ä»æ•°æ®åº“è¯»å–æ–‡æ¡£åˆ—è¡¨ï¼ˆé€šè¿‡ skip/limit åšç®€å•åˆ†é¡µï¼‰ã€‚",
    responses={
        200: {"description": "æ–‡æ¡£åˆ—è¡¨ã€‚"},
    },
)
async def list_documents(
    skip: int = 0,
    limit: int = 100,
    db: Session = Depends(get_db)
):
    """è·å–æ–‡æ¡£åˆ—è¡¨ã€‚

    å‚æ•°ï¼š
        skip: offsetã€‚
        limit: è¿”å›æ¡æ•°ä¸Šé™ã€‚
        db: SQLAlchemy ä¼šè¯ã€‚

    è¿”å›ï¼š
        æ–‡æ¡£åˆ—è¡¨ï¼ˆå½“å‰å®ç°æœªæ˜¾å¼æ’åºï¼Œé¡ºåºç”±æ•°æ®åº“é»˜è®¤è¡Œä¸ºå†³å®šï¼‰ã€‚
    """
    docs = db.query(Document).offset(skip).limit(limit).all()
    
    return [
        DocumentResponse(
            id=str(doc.id),
            filename=doc.filename,
            mime_type=doc.mime_type,
            file_size=doc.file_size,
            status=doc.status.value,
            created_at=doc.created_at.isoformat()
        )
        for doc in docs
    ]


@app.get(
    "/v1/chunk-profiles",
    response_model=List[ChunkProfileResponse],
    tags=[TAGS_CHUNK_PROFILES],
    summary="è·å–åˆ†å—ç­–ç•¥åˆ—è¡¨",
    description="è¿”å›å…¨éƒ¨ chunk profilesï¼›å…¶ä¸­æœ€å¤šä¸€ä¸ªå¯å¤„äºæ¿€æ´»çŠ¶æ€ï¼ˆis_active=trueï¼‰ã€‚",
)
async def list_chunk_profiles(db: Session = Depends(get_db)):
    """List all chunk profiles."""
    profiles = db.query(ChunkProfile).all()
    
    return [
        ChunkProfileResponse(
            id=str(p.id),
            name=p.name,
            description=p.description,
            chunk_size=p.chunk_size,
            chunk_overlap=p.chunk_overlap,
            is_active=p.is_active,
            created_at=p.created_at.isoformat()
        )
        for p in profiles
    ]


@app.post(
    "/v1/chunk-profiles",
    response_model=ChunkProfileResponse,
    tags=[TAGS_CHUNK_PROFILES],
    summary="åˆ›å»ºåˆ†å—ç­–ç•¥",
    description=(
        "åˆ›å»ºæ–°çš„ chunk profileã€‚æ–°å»º profile é»˜è®¤ä¸æ¿€æ´»ã€‚"
        "è¦åˆ‡æ¢ä¸ºç”Ÿæ•ˆç­–ç•¥ï¼Œè¯·è°ƒç”¨ `POST /v1/chunk-profiles/{profile_id}/activate`ã€‚"
    ),
    responses={
        400: {"description": "Profile name already exists."},
        200: {"description": "Chunk profile created."},
    },
)
async def create_chunk_profile(
    profile: ChunkProfileCreate,
    db: Session = Depends(get_db)
):
    """åˆ›å»ºæ–°çš„ chunk profileã€‚

    å‚æ•°ï¼š
        profile: åˆ†å—é…ç½®ã€‚
        db: SQLAlchemy ä¼šè¯ã€‚

    è¿”å›ï¼š
        åˆ›å»ºåçš„ profileã€‚
    """
    # Check if name already exists
    existing = db.query(ChunkProfile).filter(ChunkProfile.name == profile.name).first()
    if existing:
        raise HTTPException(status_code=400, detail="Profile name already exists")
    
    new_profile = ChunkProfile(
        id=uuid4(),
        name=profile.name,
        description=profile.description,
        chunk_size=profile.chunk_size,
        chunk_overlap=profile.chunk_overlap,
        is_active=False,
        created_at=datetime.utcnow(),
        updated_at=datetime.utcnow()
    )
    db.add(new_profile)
    db.commit()
    db.refresh(new_profile)
    
    return ChunkProfileResponse(
        id=str(new_profile.id),
        name=new_profile.name,
        description=new_profile.description,
        chunk_size=new_profile.chunk_size,
        chunk_overlap=new_profile.chunk_overlap,
        is_active=new_profile.is_active,
        created_at=new_profile.created_at.isoformat()
    )


@app.post(
    "/v1/chunk-profiles/{profile_id}/activate",
    tags=[TAGS_CHUNK_PROFILES],
    summary="æ¿€æ´»åˆ†å—ç­–ç•¥",
    description=(
        "å°†æŒ‡å®š profile è®¾ä¸ºæ¿€æ´»ï¼Œå¹¶å°†å…¶ä»– profile å…¨éƒ¨è®¾ä¸ºéæ¿€æ´»ã€‚"
        "å½“æ£€ç´¢/å¯¹è¯æ¥å£æœªæ˜¾å¼æŒ‡å®š profile æ—¶ï¼Œä¼šä½¿ç”¨å½“å‰æ¿€æ´»çš„ profileã€‚"
    ),
    responses={
        200: {"description": "Profile activated."},
        404: {"description": "Profile not found."},
    },
)
async def activate_chunk_profile(
    profile_id: str,
    db: Session = Depends(get_db)
):
    """æ¿€æ´» chunk profileã€‚

    ä¼šæ›´æ–°æ•°æ®åº“ï¼Œä¿è¯ä»…ä¸€ä¸ª profile å¤„äº `is_active=true`ã€‚

    å‚æ•°ï¼š
        profile_id: chunk profile UUIDã€‚
        db: SQLAlchemy ä¼šè¯ã€‚

    è¿”å›ï¼š
        ç®€å• JSON ç¡®è®¤æ¿€æ´»æˆåŠŸã€‚
    """
    profile = db.query(ChunkProfile).filter(ChunkProfile.id == profile_id).first()
    if not profile:
        raise HTTPException(status_code=404, detail="Profile not found")
    
    # Deactivate all profiles
    db.query(ChunkProfile).update({ChunkProfile.is_active: False})
    
    # Activate this profile
    profile.is_active = True
    profile.updated_at = datetime.utcnow()
    db.commit()
    
    return {"status": "activated", "profile_id": str(profile.id)}


@app.post(
    "/v1/reindex",
    tags=[TAGS_REINDEX],
    summary="è§¦å‘é‡å»ºç´¢å¼•",
    description=(
        "å¯¹é€‰å®šæ–‡æ¡£å‘å¸ƒ reindex äº‹ä»¶åˆ° Kafkaã€‚"
        "è‹¥ä¸ä¼  document_idsï¼Œåˆ™é»˜è®¤å¯¹æ‰€æœ‰ READY æ–‡æ¡£è§¦å‘é‡å»ºç´¢å¼•ã€‚"
    ),
    responses={
        200: {"description": "Reindex events published."},
    },
)
async def reindex_documents(
    request: ReindexRequest,
    db: Session = Depends(get_db)
):
    """è§¦å‘é‡å»ºç´¢å¼•ï¼ˆå¼‚æ­¥ï¼‰ã€‚

    è¯¥æ¥å£ä»…è´Ÿè´£å‘å¸ƒ Kafka æ¶ˆæ¯ï¼Œä¸ä¼šåœ¨è¯·æ±‚å‘¨æœŸå†…åš embedding è®¡ç®—ã€‚

    å‚æ•°ï¼š
        request: ç›®æ ‡ chunk_profile ä»¥åŠå¯é€‰è¿‡æ»¤æ¡ä»¶ã€‚
        db: SQLAlchemy ä¼šè¯ã€‚

    è¿”å›ï¼š
        è§¦å‘ç»“æœæ±‡æ€»ï¼ˆæ–‡æ¡£æ•°é‡ç­‰ï¼‰ã€‚
    """
    # Get documents to reindex
    if request.document_ids:
        docs = db.query(Document).filter(Document.id.in_(request.document_ids)).all()
    else:
        # Reindex all ready documents
        docs = db.query(Document).filter(Document.status == DocumentStatus.READY).all()
    
    # Send reindex events
    for doc in docs:
        send_reindex_event(
            str(doc.id),
            request.chunk_profile_id,
            request.embedding_model
        )
    
    return {
        "status": "reindex_triggered",
        "document_count": len(docs),
        "chunk_profile_id": request.chunk_profile_id
    }


@app.get(
    "/v1/chat/stream",
    tags=[TAGS_CHAT],
    summary="æµå¼å¯¹è¯ï¼ˆSSEï¼‰",
    description=(
        "é€šè¿‡ Server-Sent Events (SSE) æµå¼è¿”å›å¯¹è¯ç»“æœã€‚"
        "æœåŠ¡ç«¯ä¼šå…ˆä»å‘é‡ç´¢å¼•æ£€ç´¢ç›¸å…³ chunkï¼Œæ„å»º RAG promptï¼Œç„¶åä» LLM æµå¼è¾“å‡º tokenã€‚"
        "\n\näº‹ä»¶æ ¼å¼ï¼šæ¯è¡Œ SSE çš„ `data:` æ˜¯ä¸€ä¸ª JSONï¼Œå¯¹åº”ä¸åŒ `type`ï¼ˆtoken/citations/errorï¼‰ã€‚"
    ),
)
async def chat_stream(
    query: str = Query(...),
    top_k: Optional[int] = Query(None),
    chunk_profile_id: Optional[str] = Query(None),
    db: Session = Depends(get_db)
):
    """æµå¼å¯¹è¯æ¥å£ï¼ˆSSEï¼‰ã€‚

    Query å‚æ•°ï¼š
        query: ç”¨æˆ·é—®é¢˜ã€‚
        top_k: å¯é€‰ï¼Œæ£€ç´¢è¿”å› chunk æ•°é‡ã€‚
        chunk_profile_id: å¯é€‰ï¼ŒæŒ‡å®š chunk profileï¼›ä¸ºç©ºåˆ™ä½¿ç”¨å½“å‰æ¿€æ´» profileã€‚

    SSE æµè¿”å›ï¼š
        - `data: {"type": "token", "content": "..."}`ï¼šé€ token è¾“å‡ºã€‚
        - `data: {"type": "citations", "citations": [...]}`ï¼šæœ€ç»ˆå¼•ç”¨æ¥æºã€‚
        - `data: [DONE]`ï¼šç»“æŸæ ‡è®°ã€‚

    è¿”å›ï¼š
        `text/event-stream` çš„ SSE å“åº”ã€‚
    """
    
    async def generate():
        try:
            # Get active chunk profile if not specified
            if not chunk_profile_id:
                active_profile = db.query(ChunkProfile).filter(ChunkProfile.is_active == True).first()
                if not active_profile:
                    yield f"data: {json.dumps({'type': 'error', 'content': 'No active chunk profile'})}\n\n"
                    return
                profile_id = str(active_profile.id)
            else:
                profile_id = chunk_profile_id
            
            # Retrieve relevant chunks
            results = retrieve_chunks(
                db=db,
                query=query,
                chunk_profile_id=profile_id,
                top_k=top_k
            )
            
            if not results:
                yield f"data: {json.dumps({'type': 'token', 'content': 'No relevant information found.'})}\n\n"
                yield f"data: {json.dumps({'type': 'citations', 'citations': []})}\n\n"
                yield "data: [DONE]\n\n"
                return
            
            # Build context
            context = build_rag_context(results)
            
            # Build prompt
            messages = build_rag_prompt(query, context)
            
            # Stream response from vLLM
            vllm_client = get_vllm_client()
            
            for token in vllm_client.chat_stream(messages, max_tokens=512, temperature=0.7):
                yield f"data: {json.dumps({'type': 'token', 'content': token})}\n\n"
            
            # Send citations
            citations = format_citations(results)
            yield f"data: {json.dumps({'type': 'citations', 'citations': citations})}\n\n"
            
            yield "data: [DONE]\n\n"
        
        except Exception as e:
            logger.error(f"Error in chat stream: {e}", exc_info=True)
            yield f"data: {json.dumps({'type': 'error', 'content': str(e)})}\n\n"
    
    return EventSourceResponse(generate())


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host=settings.app_host, port=settings.app_port)
